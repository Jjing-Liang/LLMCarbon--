# Title

## Introduction

Since the introduction of ChatGPT, the Large Language Model (LLM) has evolved rapidly - GPT-4, LLama, Claude, Gemini, Mistral, Grok-1 - one new model after another is influencing the whole society. At the same time, the impact of LLM on the environment has also been hotly debated. At this stage, there are many studies or articles discussing the impact of AI/ML/LLM on the environment. A study at the University of Washington (https://www.washington.edu/news/2023/07/27/how-much-energy-does-chatgpt-use/) shows that training just one chatbot can consume a year's worth of electricity in a neighborhood. The actual carbon emissions generated behind the scenes are still not transparent today.

We describe the process of calculating carbon emissions from the perspective of the LLM's lifecycle in the two main phases of carbon generation: training and reasoning, while using the [Green Software Foundation](https://greensoftware.foundation/)'s [Impact framework](https://greensoftware.foundation/) tool to create a framework that can be used to calculate the carbon emissions of a chatbot. (https://if.greensoftware.foundation/) created a demo of the LLM life cycle carbon emissions for your reference. In the process of gathering information, we have compiled an up-to-date dataset containing the carbon emissions of existing LLMs, and a summary of publicly available data related to carbon emissions calculations (Chip Thermal Design Power, PUE, Carbon intensity, etc.). We hope that the key information presented in this blog will help you understand the carbon footprint of LLMs from an environmentally responsible perspective, so that you can train and use LLMs wisely.


## Methodology for estimating LLM carbon emissions

## Using Impact Framework for estimation

## Conclusion

## Reference